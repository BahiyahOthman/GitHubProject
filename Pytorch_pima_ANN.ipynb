{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt](https://research.utm.my/wp-content/uploads/sites/26/2022/06/logo-300x122.png)\n",
    "# Center for Artificial Intelligence and Robotics\n",
    "#### Universiti Teknologi Malaysia\n",
    "\n",
    "\n",
    "### ANN Classification\n",
    "\n",
    "*Author: Dr. Ibrahim, Azzam, Thaqif & Syahmi*\n",
    "\n",
    "**PIMA Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vc_w1_1jCPE2"
   },
   "source": [
    "**Import Package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PA17lvrtxEAZ"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27XDgSMjCVNH"
   },
   "source": [
    "**Install Package and Obtain Processing Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5Ov_2y-A7X6",
    "outputId": "9f750446-58e8-46d6-e731-d32055305736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (8.26.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.14.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->ipython-autotime) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython->ipython-autotime) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython->ipython-autotime) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython->ipython-autotime) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from asttokens>=2.1.0->stack-data->ipython->ipython-autotime) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime --index-url https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rz9CeYFiA9ec",
    "outputId": "f78d6a5e-1135-4c04-deba-02c1ec55c89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 393 μs (started: 2025-07-15 06:48:54 +00:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Dno01fUTM3l"
   },
   "source": [
    "**Download PIMA dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcV0nYnxTaLt",
    "outputId": "b782e342-4c2c-46be-ebfd-441904837c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to dataset/pima_indians_diabetes.csv\n",
      "time: 286 ms (started: 2025-07-15 06:49:00 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "df = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "#Define the output path and create directories if they don't exist\n",
    "output_dir = 'dataset'\n",
    "output_path = os.path.join(output_dir, 'pima_indians_diabetes.csv')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save the dataset to Google Drive as a CSV file\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dataset saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1XYbFhnCnmJ"
   },
   "source": [
    "**Read data in pandas and Display the first few lines of data .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5tLVIFgHRHH",
    "outputId": "826fafab-8231-44f6-8721-7d7d2f83b4bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.8 ms (started: 2025-07-15 06:49:08 +00:00)\n"
     ]
    }
   ],
   "source": [
    "sample_df = pd.read_csv('dataset/pima_indians_diabetes.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "moMo-snCH1QV",
    "outputId": "18e0a2a7-8b3d-4378-a3b0-51dbcf2a44aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43.6 ms (started: 2025-07-15 06:49:11 +00:00)\n"
     ]
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr-taqifCwCY"
   },
   "source": [
    "**Define the input, X and label as Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTE8t3K-H-2-",
    "outputId": "d655334c-d8d2-4fa0-8841-e2a5c011647c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy X: [[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
      " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
      " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
      " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
      " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
      "NumPy Y: [1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "PyTorch X_tensor: tensor([[  6.0000, 148.0000,  72.0000,  ...,  33.6000,   0.6270,  50.0000],\n",
      "        [  1.0000,  85.0000,  66.0000,  ...,  26.6000,   0.3510,  31.0000],\n",
      "        [  8.0000, 183.0000,  64.0000,  ...,  23.3000,   0.6720,  32.0000],\n",
      "        ...,\n",
      "        [  5.0000, 121.0000,  72.0000,  ...,  26.2000,   0.2450,  30.0000],\n",
      "        [  1.0000, 126.0000,  60.0000,  ...,  30.1000,   0.3490,  47.0000],\n",
      "        [  1.0000,  93.0000,  70.0000,  ...,  30.4000,   0.3150,  23.0000]])\n",
      "PyTorch Y_tensor: tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "time: 6.06 s (started: 2025-07-15 06:49:27 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dataset = sample_df.values\n",
    "X = dataset[:,0:8].astype(float)\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# Print the NumPy arrays\n",
    "print(\"NumPy X:\", X)\n",
    "print(\"NumPy Y:\", Y)\n",
    "\n",
    "# Step 4: Convert NumPy arrays to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.float32).view(-1, 1) # Y_tensor is reshaped to ensure compatibility with the model's output and loss calculation\n",
    "\n",
    "\n",
    "# Print the PyTorch tensors\n",
    "print(\"PyTorch X_tensor:\", X_tensor)\n",
    "print(\"PyTorch Y_tensor:\", Y_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBuDnghKC6I9"
   },
   "source": [
    "**Import Package for Pytorch to design ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "time: 3.32 s (started: 2025-07-15 06:49:33 +00:00)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn --index-url https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "time: 3.34 s (started: 2025-07-15 06:49:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib --index-url https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFLHcsGwivQh",
    "outputId": "b0773220-54d0-410a-9806-cc7647b976a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.78 s (started: 2025-07-15 06:49:49 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMwbEsdCYoFR",
    "outputId": "3dfd4271-93e6-4cec-90a8-a53a731d889e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.22 ms (started: 2025-07-15 06:54:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "input_dim = 8\n",
    "hidden_dim1 = 12\n",
    "hidden_dim2 = 8\n",
    "output_dim = 1\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JV_IcBaCDEvp"
   },
   "source": [
    "**Create Class for dataset and dataloader**\n",
    "\n",
    "DataLoader is a fundamental part of the data loading utility that makes it easier to iterate over batches of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2AxtPY8gVaY",
    "outputId": "3b7d1827-b535-4ded-dd1f-be35f2d5075e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.07 ms (started: 2025-07-15 06:50:02 +00:00)\n"
     ]
    }
   ],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        # In the initialization method, we define how to load our dataset.\n",
    "        # Here, we use data.drop() to identify and exclude the 'Outcome' column, extracting features and labels.\n",
    "        self.features = torch.tensor(data.drop('Outcome', axis=1).values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(data['Outcome'].values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-Tj2AdOfpoE",
    "outputId": "226a99bd-f672-4b79-d98a-bf6795073831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.9 ms (started: 2025-07-15 06:50:05 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming DiabetesDataset and sample_df are defined properly\n",
    "diabetes_dataset = DiabetesDataset(sample_df)\n",
    "\n",
    "# Define the sizes of the splits\n",
    "total_size = len(diabetes_dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_data, temp_data = random_split(diabetes_dataset, [train_size, val_size + test_size])\n",
    "val_data, test_data = random_split(temp_data, [val_size, test_size])\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COhx7OdYDlpt"
   },
   "source": [
    "**Create ANN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjPYOaNmlEQ0",
    "outputId": "bb6b8e2f-1b19-4530-ce0b-4e4341906259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.58 ms (started: 2025-07-15 06:50:16 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Define the PyTorch model\n",
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDfQNQFCZOKx",
    "outputId": "e3653084-ff01-4c2d-f4e4-eb36a4255a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNModel(\n",
      "  (fc1): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "time: 2.25 s (started: 2025-07-15 06:50:26 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the neural network\n",
    "model = ANNModel(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0worgLFaooh"
   },
   "source": [
    "**Path to save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-10xzKda2Rh",
    "outputId": "4ca487b9-67de-4507-d076-5110cca89fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 955 μs (started: 2025-07-15 06:50:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the model\n",
    "model_path = 'model/pima_model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtO6hCbbDq18"
   },
   "source": [
    "**Define Optimizer and Loss Function for Training Phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnRaKBEGlRPo",
    "outputId": "47b8e640-b46b-4ef8-9558-00ebfc5fd97f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.7 ms (started: 2025-07-15 06:50:49 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    predicted = outputs.round()\n",
    "    correct = (predicted == labels).float().sum()\n",
    "    accuracy = correct / labels.size(0)\n",
    "    return accuracy.item()\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(7)\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaMMXnJ0Xmi4",
    "outputId": "3b753054-b810-4c55-a8bc-c69a8ed28144",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.4165, Accuracy: 0.7902, Validation Loss: 1.5072, Validation Accuracy: 0.7743\n",
      "Epoch [2/100], Loss: 0.4152, Accuracy: 0.7997, Validation Loss: 1.4875, Validation Accuracy: 0.7917\n",
      "Epoch [3/100], Loss: 0.4176, Accuracy: 0.7965, Validation Loss: 1.4813, Validation Accuracy: 0.8021\n",
      "Epoch [4/100], Loss: 0.4151, Accuracy: 0.8086, Validation Loss: 1.5718, Validation Accuracy: 0.7639\n",
      "Epoch [5/100], Loss: 0.4270, Accuracy: 0.7900, Validation Loss: 1.5814, Validation Accuracy: 0.7639\n",
      "Epoch [6/100], Loss: 0.4216, Accuracy: 0.7984, Validation Loss: 0.5551, Validation Accuracy: 0.7847\n",
      "Epoch [7/100], Loss: 0.4389, Accuracy: 0.7829, Validation Loss: 1.5710, Validation Accuracy: 0.7465\n",
      "Epoch [8/100], Loss: 0.4209, Accuracy: 0.7892, Validation Loss: 1.5047, Validation Accuracy: 0.7847\n",
      "Epoch [9/100], Loss: 0.4284, Accuracy: 0.7790, Validation Loss: 1.4822, Validation Accuracy: 0.7743\n",
      "Epoch [10/100], Loss: 0.4173, Accuracy: 0.7944, Validation Loss: 1.5172, Validation Accuracy: 0.7639\n",
      "Epoch [11/100], Loss: 0.4210, Accuracy: 0.8021, Validation Loss: 1.5203, Validation Accuracy: 0.7535\n",
      "Epoch [12/100], Loss: 0.4131, Accuracy: 0.7957, Validation Loss: 1.5040, Validation Accuracy: 0.7639\n",
      "Epoch [13/100], Loss: 0.4117, Accuracy: 0.8031, Validation Loss: 1.4912, Validation Accuracy: 0.7743\n",
      "Epoch [14/100], Loss: 0.4114, Accuracy: 0.8104, Validation Loss: 1.5177, Validation Accuracy: 0.7639\n",
      "Epoch [15/100], Loss: 0.4208, Accuracy: 0.8049, Validation Loss: 1.4889, Validation Accuracy: 0.7917\n",
      "Epoch [16/100], Loss: 0.4199, Accuracy: 0.7932, Validation Loss: 1.6322, Validation Accuracy: 0.7535\n",
      "Epoch [17/100], Loss: 0.4279, Accuracy: 0.7976, Validation Loss: 1.5024, Validation Accuracy: 0.7431\n",
      "Epoch [18/100], Loss: 0.4210, Accuracy: 0.8063, Validation Loss: 0.5971, Validation Accuracy: 0.7951\n",
      "Epoch [19/100], Loss: 0.4143, Accuracy: 0.8101, Validation Loss: 1.5130, Validation Accuracy: 0.7535\n",
      "Epoch [20/100], Loss: 0.4131, Accuracy: 0.8089, Validation Loss: 1.4965, Validation Accuracy: 0.7812\n",
      "Epoch [21/100], Loss: 0.4124, Accuracy: 0.8099, Validation Loss: 1.5038, Validation Accuracy: 0.7639\n",
      "Epoch [22/100], Loss: 0.4116, Accuracy: 0.8107, Validation Loss: 1.4759, Validation Accuracy: 0.8021\n",
      "Epoch [23/100], Loss: 0.4119, Accuracy: 0.8057, Validation Loss: 1.5438, Validation Accuracy: 0.7535\n",
      "Epoch [24/100], Loss: 0.4162, Accuracy: 0.7992, Validation Loss: 1.4866, Validation Accuracy: 0.7917\n",
      "Epoch [25/100], Loss: 0.4143, Accuracy: 0.8057, Validation Loss: 1.4736, Validation Accuracy: 0.8021\n",
      "Epoch [26/100], Loss: 0.4162, Accuracy: 0.8073, Validation Loss: 1.5432, Validation Accuracy: 0.7535\n",
      "Epoch [27/100], Loss: 0.4150, Accuracy: 0.8021, Validation Loss: 1.4977, Validation Accuracy: 0.7639\n",
      "Epoch [28/100], Loss: 0.4138, Accuracy: 0.8044, Validation Loss: 1.4925, Validation Accuracy: 0.7743\n",
      "Epoch [29/100], Loss: 0.4283, Accuracy: 0.8015, Validation Loss: 1.5144, Validation Accuracy: 0.7535\n",
      "Epoch [30/100], Loss: 0.4378, Accuracy: 0.7763, Validation Loss: 1.5165, Validation Accuracy: 0.7639\n",
      "Epoch [31/100], Loss: 0.4278, Accuracy: 0.7850, Validation Loss: 0.5810, Validation Accuracy: 0.7847\n",
      "Epoch [32/100], Loss: 0.4303, Accuracy: 0.7850, Validation Loss: 1.4913, Validation Accuracy: 0.7951\n",
      "Epoch [33/100], Loss: 0.4163, Accuracy: 0.8063, Validation Loss: 1.5532, Validation Accuracy: 0.7639\n",
      "Epoch [34/100], Loss: 0.4185, Accuracy: 0.8031, Validation Loss: 1.5031, Validation Accuracy: 0.7639\n",
      "Epoch [35/100], Loss: 0.4107, Accuracy: 0.8031, Validation Loss: 1.4942, Validation Accuracy: 0.7639\n",
      "Epoch [36/100], Loss: 0.4121, Accuracy: 0.8049, Validation Loss: 1.5440, Validation Accuracy: 0.7639\n",
      "Epoch [37/100], Loss: 0.4155, Accuracy: 0.8089, Validation Loss: 1.4770, Validation Accuracy: 0.7743\n",
      "Epoch [38/100], Loss: 0.4122, Accuracy: 0.8102, Validation Loss: 1.5297, Validation Accuracy: 0.7639\n",
      "Epoch [39/100], Loss: 0.4121, Accuracy: 0.8178, Validation Loss: 1.5505, Validation Accuracy: 0.7639\n",
      "Epoch [40/100], Loss: 0.4179, Accuracy: 0.7976, Validation Loss: 0.5801, Validation Accuracy: 0.7743\n",
      "Epoch [41/100], Loss: 0.4138, Accuracy: 0.7984, Validation Loss: 1.4997, Validation Accuracy: 0.7917\n",
      "Epoch [42/100], Loss: 0.4107, Accuracy: 0.8076, Validation Loss: 1.5390, Validation Accuracy: 0.7639\n",
      "Epoch [43/100], Loss: 0.4109, Accuracy: 0.8096, Validation Loss: 1.5076, Validation Accuracy: 0.7535\n",
      "Epoch [44/100], Loss: 0.4157, Accuracy: 0.8054, Validation Loss: 1.4860, Validation Accuracy: 0.8021\n",
      "Epoch [45/100], Loss: 0.4113, Accuracy: 0.8123, Validation Loss: 1.4937, Validation Accuracy: 0.7743\n",
      "Epoch [46/100], Loss: 0.4088, Accuracy: 0.8118, Validation Loss: 1.4966, Validation Accuracy: 0.7743\n",
      "Epoch [47/100], Loss: 0.4124, Accuracy: 0.8081, Validation Loss: 1.4989, Validation Accuracy: 0.7639\n",
      "Epoch [48/100], Loss: 0.4113, Accuracy: 0.8034, Validation Loss: 1.5064, Validation Accuracy: 0.7535\n",
      "Epoch [49/100], Loss: 0.4110, Accuracy: 0.8086, Validation Loss: 1.4910, Validation Accuracy: 0.7917\n",
      "Epoch [50/100], Loss: 0.4100, Accuracy: 0.8081, Validation Loss: 1.4911, Validation Accuracy: 0.8021\n",
      "Epoch [51/100], Loss: 0.4080, Accuracy: 0.8044, Validation Loss: 1.4984, Validation Accuracy: 0.7743\n",
      "Epoch [52/100], Loss: 0.4086, Accuracy: 0.8007, Validation Loss: 1.5235, Validation Accuracy: 0.7639\n",
      "Epoch [53/100], Loss: 0.4109, Accuracy: 0.8071, Validation Loss: 1.4932, Validation Accuracy: 0.8021\n",
      "Epoch [54/100], Loss: 0.4096, Accuracy: 0.8136, Validation Loss: 1.5301, Validation Accuracy: 0.7639\n",
      "Epoch [55/100], Loss: 0.4060, Accuracy: 0.8110, Validation Loss: 1.4809, Validation Accuracy: 0.8021\n",
      "Epoch [56/100], Loss: 0.4099, Accuracy: 0.8128, Validation Loss: 1.4766, Validation Accuracy: 0.7639\n",
      "Epoch [57/100], Loss: 0.4144, Accuracy: 0.8107, Validation Loss: 1.5640, Validation Accuracy: 0.7535\n",
      "Epoch [58/100], Loss: 0.4116, Accuracy: 0.7984, Validation Loss: 1.4702, Validation Accuracy: 0.7743\n",
      "Epoch [59/100], Loss: 0.4175, Accuracy: 0.7989, Validation Loss: 1.5005, Validation Accuracy: 0.8021\n",
      "Epoch [60/100], Loss: 0.4142, Accuracy: 0.8094, Validation Loss: 1.5949, Validation Accuracy: 0.7639\n",
      "Epoch [61/100], Loss: 0.4118, Accuracy: 0.8160, Validation Loss: 1.4767, Validation Accuracy: 0.7847\n",
      "Epoch [62/100], Loss: 0.4161, Accuracy: 0.8044, Validation Loss: 1.5067, Validation Accuracy: 0.7743\n",
      "Epoch [63/100], Loss: 0.4113, Accuracy: 0.8039, Validation Loss: 1.4827, Validation Accuracy: 0.8021\n",
      "Epoch [64/100], Loss: 0.4082, Accuracy: 0.8049, Validation Loss: 1.4890, Validation Accuracy: 0.8021\n",
      "Epoch [65/100], Loss: 0.4115, Accuracy: 0.8068, Validation Loss: 1.4852, Validation Accuracy: 0.8021\n",
      "Epoch [66/100], Loss: 0.4114, Accuracy: 0.8073, Validation Loss: 1.5792, Validation Accuracy: 0.7535\n",
      "Epoch [67/100], Loss: 0.4200, Accuracy: 0.7965, Validation Loss: 1.5168, Validation Accuracy: 0.7639\n",
      "Epoch [68/100], Loss: 0.4068, Accuracy: 0.8094, Validation Loss: 1.4830, Validation Accuracy: 0.7917\n",
      "Epoch [69/100], Loss: 0.4107, Accuracy: 0.8107, Validation Loss: 1.4927, Validation Accuracy: 0.7639\n",
      "Epoch [70/100], Loss: 0.4094, Accuracy: 0.8110, Validation Loss: 1.4763, Validation Accuracy: 0.7917\n",
      "Epoch [71/100], Loss: 0.4098, Accuracy: 0.8086, Validation Loss: 1.5053, Validation Accuracy: 0.7639\n",
      "Epoch [72/100], Loss: 0.4160, Accuracy: 0.7942, Validation Loss: 1.5546, Validation Accuracy: 0.7535\n",
      "Epoch [73/100], Loss: 0.4163, Accuracy: 0.7929, Validation Loss: 1.5152, Validation Accuracy: 0.7639\n",
      "Epoch [74/100], Loss: 0.4231, Accuracy: 0.7997, Validation Loss: 0.5929, Validation Accuracy: 0.7951\n",
      "Epoch [75/100], Loss: 0.4193, Accuracy: 0.7913, Validation Loss: 1.4935, Validation Accuracy: 0.7847\n",
      "Epoch [76/100], Loss: 0.4141, Accuracy: 0.8002, Validation Loss: 1.5429, Validation Accuracy: 0.7535\n",
      "Epoch [77/100], Loss: 0.4191, Accuracy: 0.8089, Validation Loss: 1.5302, Validation Accuracy: 0.7743\n",
      "Epoch [78/100], Loss: 0.4214, Accuracy: 0.7984, Validation Loss: 1.4690, Validation Accuracy: 0.7743\n",
      "Epoch [79/100], Loss: 0.4175, Accuracy: 0.8002, Validation Loss: 0.5896, Validation Accuracy: 0.7639\n",
      "Epoch [80/100], Loss: 0.4191, Accuracy: 0.7900, Validation Loss: 1.5542, Validation Accuracy: 0.7639\n",
      "Epoch [81/100], Loss: 0.4094, Accuracy: 0.8012, Validation Loss: 1.4679, Validation Accuracy: 0.8021\n",
      "Epoch [82/100], Loss: 0.4173, Accuracy: 0.8081, Validation Loss: 1.5485, Validation Accuracy: 0.7639\n",
      "Epoch [83/100], Loss: 0.4197, Accuracy: 0.7997, Validation Loss: 1.6082, Validation Accuracy: 0.7535\n",
      "Epoch [84/100], Loss: 0.4150, Accuracy: 0.8004, Validation Loss: 1.4731, Validation Accuracy: 0.8125\n",
      "Epoch [85/100], Loss: 0.4249, Accuracy: 0.7997, Validation Loss: 1.4931, Validation Accuracy: 0.7743\n",
      "Epoch [86/100], Loss: 0.4063, Accuracy: 0.8215, Validation Loss: 1.5252, Validation Accuracy: 0.7743\n",
      "Epoch [87/100], Loss: 0.4120, Accuracy: 0.7944, Validation Loss: 1.5161, Validation Accuracy: 0.7639\n",
      "Epoch [88/100], Loss: 0.4132, Accuracy: 0.7931, Validation Loss: 1.4744, Validation Accuracy: 0.8021\n",
      "Epoch [89/100], Loss: 0.4055, Accuracy: 0.8123, Validation Loss: 1.5358, Validation Accuracy: 0.7639\n",
      "Epoch [90/100], Loss: 0.4062, Accuracy: 0.8144, Validation Loss: 1.4746, Validation Accuracy: 0.7743\n",
      "Epoch [91/100], Loss: 0.4130, Accuracy: 0.8071, Validation Loss: 1.5527, Validation Accuracy: 0.7743\n",
      "Epoch [92/100], Loss: 0.4111, Accuracy: 0.8018, Validation Loss: 1.4802, Validation Accuracy: 0.8021\n",
      "Epoch [93/100], Loss: 0.4095, Accuracy: 0.8099, Validation Loss: 1.4792, Validation Accuracy: 0.7639\n",
      "Epoch [94/100], Loss: 0.4063, Accuracy: 0.8141, Validation Loss: 1.5864, Validation Accuracy: 0.7639\n",
      "Epoch [95/100], Loss: 0.4211, Accuracy: 0.8081, Validation Loss: 1.4771, Validation Accuracy: 0.7743\n",
      "Epoch [96/100], Loss: 0.4144, Accuracy: 0.7997, Validation Loss: 1.4962, Validation Accuracy: 0.7639\n",
      "Epoch [97/100], Loss: 0.4141, Accuracy: 0.8141, Validation Loss: 1.4957, Validation Accuracy: 0.7639\n",
      "Epoch [98/100], Loss: 0.4133, Accuracy: 0.8052, Validation Loss: 1.5164, Validation Accuracy: 0.7743\n",
      "Epoch [99/100], Loss: 0.4096, Accuracy: 0.8196, Validation Loss: 1.4875, Validation Accuracy: 0.7743\n",
      "Epoch [100/100], Loss: 0.4086, Accuracy: 0.8034, Validation Loss: 1.4788, Validation Accuracy: 0.7917\n",
      "Training complete. Average Loss: 0.4151, Best Validation Accuracy: 0.8125\n",
      "time: 5.74 s (started: 2025-07-15 06:54:27 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store loss and accuracy\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "    for i, (input, labels) in enumerate(train_loader):  # Renamed 'features' to 'input'\n",
    "        # Forward pass\n",
    "        outputs = model(input)\n",
    "\n",
    "        # Reshape labels to match the shape of model outputs and convert to Float\n",
    "        labels = labels.unsqueeze(1).float()  # Add an extra dimension and convert to Float\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate batch accuracy\n",
    "        accuracy = calculate_accuracy(outputs, labels)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += accuracy\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_accuracy /= len(train_loader)\n",
    "\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    epoch_accuracies.append(epoch_accuracy)\n",
    "\n",
    "    # Validation\n",
    "    val_loss = 0.0  # Initialize validation loss variable\n",
    "    val_accuracy = 0.0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for input_val, labels_val in val_loader:\n",
    "            outputs_val = model(input_val)\n",
    "            loss_val = criterion(outputs_val, labels_val.unsqueeze(1).float())  # Compute validation loss\n",
    "            accuracy_val = calculate_accuracy(outputs_val, labels_val.unsqueeze(1).float())  # Adjust labels shape and convert to Float\n",
    "            val_loss += loss_val.item()  # Accumulate validation loss\n",
    "            val_accuracy += accuracy_val\n",
    "        val_loss /= len(val_loader)  # Compute average validation loss\n",
    "        val_losses.append(val_loss)  # Store validation loss\n",
    "        val_accuracy /= len(val_loader)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "    # Save model if validation accuracy improves\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_model_params = model.state_dict()\n",
    "        torch.save(best_model_params, model_path)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "\n",
    "# Print final results\n",
    "avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "print(f\"Training complete. Average Loss: {avg_loss:.4f}, Best Validation Accuracy: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aXMUf1ODzDl"
   },
   "source": [
    "**Prepare Data for Validation**\n",
    "# Answer for Question 1 - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "maYN2m39ldbV",
    "outputId": "61d34620-d4d5-412b-bcee-93f96fe38e85"
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "dtest = X[400,0:8]\n",
    "dtest = np.expand_dims(dtest, axis=0)\n",
    "\n",
    "# Assuming 'model' is your trained model and 'X' is your dataset\n",
    "dtest = X[400, 0:8]\n",
    "dtest = np.expand_dims(dtest, axis=0)  # Add batch dimension\n",
    "\n",
    "# Convert dtest to a torch tensor and float type\n",
    "dtest_tensor = torch.tensor(dtest, dtype=torch.float32)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(dtest_tensor)\n",
    "\n",
    "# Since you're dealing with binary classification, assume sigmoid activation in the output layer\n",
    "score = predictions[0].item()\n",
    "\n",
    "# Calculate probabilities for each class\n",
    "other = 1 - score\n",
    "val = np.array([score, other])\n",
    "\n",
    "# Get the predicted class (0 or 1)\n",
    "classes = np.argmax(val)\n",
    "\n",
    "print(\n",
    "    \"This sample is %.2f percent Diabetic and %.2f percent NotDiabetic.\"\n",
    "    % (100 * score, 100 * other)\n",
    ")  # Will print on the Console\n",
    "\n",
    "print(\"The predicted class is: \", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEsf2h99D_nS"
   },
   "source": [
    "**Obtain Training Info for Loss and Accuracy**\n",
    "# Answer for Question 2 - Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "m2ajKX_JgjEZ",
    "outputId": "b113eb82-fbd7-4fc6-f4ae-447194a8d354"
   },
   "outputs": [],
   "source": [
    "# model is your variable that you have trained to save in model folder\n",
    "\n",
    "## Answer Here ##\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "J2VJ9qR2fc9o",
    "outputId": "587a4ced-d4d4-4e40-f1a2-90f757d93611"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have collected epoch_losses and val_losses during training and validation, respectively\n",
    "plt.plot(epoch_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri5FEJnoAwpK"
   },
   "source": [
    "# Answer for Question 3 - Plot The Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BG9y2F9yhAiQ"
   },
   "outputs": [],
   "source": [
    "# Plot Accuracy Graph\n",
    "\n",
    "plt.plot(epoch_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWS_-XnwEV3-"
   },
   "source": [
    "**Serialize the Model to gdrive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBzOhZDVEcRZ"
   },
   "source": [
    "**Check the Model in the Working Folder in gdrive**\n",
    "# Answer Question 4 - Load The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1ECLS-TaRra"
   },
   "outputs": [],
   "source": [
    "# Initialize your model instance\n",
    "loaded_model = ANNModel(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "\n",
    "# Path to the saved model on Google Drive\n",
    "model_path = 'model/pima_model.pt'\n",
    "\n",
    "# Load the state dictionary\n",
    "## Answer Here ##\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "loaded_model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYXyO2SWE5Ip"
   },
   "source": [
    "# Answer Question 5 - Prediction on the Loaded Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeLk4osldXfn"
   },
   "outputs": [],
   "source": [
    "# Question 5\n",
    "# Use the loaded model for prediction\n",
    "\n",
    "# Assuming 'model' is your trained model and 'X' is your dataset\n",
    "dtest = X[300, 0:8]\n",
    "dtest = np.expand_dims(dtest, axis=0)  # Add batch dimension\n",
    "\n",
    "# Convert dtest to a torch tensor and float type\n",
    "dtest_tensor = torch.tensor(dtest, dtype=torch.float32)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    ## Answer Here ##\n",
    "\n",
    "# Since you're dealing with binary classification, assume sigmoid activation in the output layer\n",
    "score1 = predictions[0].item()\n",
    "\n",
    "# Calculate probabilities for each class\n",
    "other1 = 1 - score1\n",
    "val1 = np.array([score1, other1])\n",
    "\n",
    "# Get the predicted class (0 or 1)\n",
    "classes1 = np.argmax(val1)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"This sample is %.2f percent Diabetic and %.2f percent NotDiabetic.\"\n",
    "    % (100 * score1, 100 * other1)\n",
    ")  # Will print on the Console\n",
    "\n",
    "print(\"The predicted class is: \", classes1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
